---
date: 2024-08-13
modified: 2024-08-16T15:42:06+02:00
---
In the last lesson we discussed alternatives to tuple-oriented storage scheme:
* Log-structured storage: instead of storing the actual tuples, you store the log entries of the changes you've made to tuples.
* Index-organized storage

These three approaches we talked about (the Tuple-Oriented slotted pages, the Log-structured storage, and the Index-organized storage), are ideal for **write-heavy** (`INSERT`/`UPDATE`/`DELETE`) workloads. But the most important query for an application may be **read performance** (`SELECT`). And these approaches may not be the best way to go.

```python
print("hello")
```
# 1. Database Workloads
Let's see some broad categories or database applications and some motivation for why we want to look at an alternative storage scheme:
* **On-Line Transaction Processing** (**OLTP**)
* **On-Line Analytical Processing** (**OLAP**)
* **Hybrid Transaction + Analytical Processing**
## 1.1. On-Line Transaction Processing (OLTP)
An OLTP workload is characterized by fast, short running operations, repetitive operations and simple queries that operate on single entity at a time. OLTP workloads typically handle more writes than reads, and only read/update a small amount of data each time.

**Example: Amazon storefront**. When you go to the Amazon website you look at products, then you click things, you add them to your card and then you purchase them and maybe you go under your account information and you go update your email address, or payment information and so on. Those operation are all considered **OLTP style workload** because you're making changes to small subset of the database.

**Example: posting things on Reddit**. It makes small changes to database (potentially huge database), but the amount of change each query is making is small and the amount of data is reading is small.
## 1.2. On-Line Analytical Processing (OLAP)
An OLAP workload is characterized by long running, complex queries and reads on large portions of the database. In OLAP workloads, the database system is often analyzing and deriving new data from existing data collected on the OLTP side. It's about running queries that extract new information across the entire dataset. OLAP operations are primarily read-heavy or read-only, so I'm not doing single updates.

**Example: retrieving stats in Amazon**. Run a query to find the number one sold product in the state of Pennsylvania on Saturday when the temperature is above 80 degrees. So, it's not looking a single person or looking at a single entity, but it's looking across the entire table, potentially doing a lot of joins.
## 1.3. Hybrid Transaction + Analytical Processing
A new type of workload (which has become popular recently) is HTAP, where OLTP and OLAP workloads are present together on the same database.
## 1.4. Visualizing Workload Types
Use a simple grid where along the x-axis we're saying wether the workload is made read-heavy vs write-heavy and on the y-axis we're saying how complex the queries are:
![](Database%20System/attachments/Pasted%20image%2020240814110204.png)

We'll talk about why the **things we talked about so far they're gonna be good for OLTP, but not for OLAP**, and then we'll design a **storage scheme that is better for OLAP**.
## 1.5. Example: Wikipedia Database
Let's make an example using a real database that is roughly what the Wikipedia database looks like:
![](Database%20System/attachments/Pasted%20image%2020240814111656.png)

## 1.6. Observations on Storage Models
The **Relational Model does not specify anything about how we should store the data in a table**: it does not specify that the DBMS must store all a tuple's attribute together in a single page. This solution may not actually be the best layout for some workloads, like OLAP workloads.
### 1.6.1. OLTP queries
**On-line Transaction processing**: simple queries that read/update a small amount of data that is related to a single entity in the database. An example:
```sql
-- example 1
SELECT P.*, R.*
FROM pages AS P
INNER JOIN revisions AS R
ON P.latest = R.revID
WHERE P.pageID = ?;

-- example 2
UPDATE useracct
SET lastLogin = NOW(),
	hostname = ?
WHERE userID = ?;
```
This kind of operations are what usually people end up with when they build a new application, like you create a startup and you start building some online service, you usually end up with something like above because you have no data in the beginning.
### 1.6.2. OLAP queries
On-line Analytical Processing: complex queries that read large portions of the database spanning multiple entities. An example to get the number of times people have logged in per month if they end with a ".gov" hostname):
```sql
SELECT COUNT(U.lastLogin),
		EXTRACT(month FROM U.lastLogin) AS month
FROM useracct AS U
WHERE U.hostname LIKE '%.gov'
GROUP BY
EXTRACT(month FROM. U.lastLogin)
```
You execute these workloads on the data you have collected from your OLTP application(s).
# 2. Storage Models
A DBMS's **Storage Model** specifies how it physically organizes tuples on disk and in memory.

Until now, we assumed that all the attributes are contiguous for a tuple and that's sort of roughly called a row-store, but for OLAP it may not be the best thing.

The reason why we have to discuss this part of as system is because there is a clear distinction in the database marketplace now between a row-store system and a column-store system:
* row-store systems are used for OLTP
* column-store systems are used for OLAP

When someone tries to sell you a row-store system that you can use for OLAP workload, you have to be very skeptical.

There are different ways to store tuples in pages. We have assumed the n-ary storage model so far:
1. N-ary Storage Model (NSM) (row-store)
2. Decomposition Storage Model (DSM) (column-store)
3. Hybrid Storage Model (PAX) (the most common for column-store)
## 2.1. N-ary Storage Model (NSM)
In the n-ary storage model, the DBMS stores all of the attributes for a single tuple contiguously in a single page (this is the assumption we're keeping from the beginning of this course).

This approach is ideal for OLTP workloads where requests are insert-heavy and transactions tend to operate only an individual entity. It is ideal because it takes only one fetch to be able to get all of the attributes for a single tuple.
### 2.1.1 NSM: Physical Organization
A disk-oriented NSM system stores a tuple's fixed-length and variable-length attributes contiguously in a single slotted page.

The following is basically the same layout we have seen before where we have a database page, an header in the front, the slot array, and then, as we start scanning the table and we want to inserting data, it's just going to go append the entries to the end and keep adding more and more (*not sure about this last sentence*). The tuple's **record is** (page#, slot#) i how the DBMS uniquely identifies a physical tuple. Let's look visually at the first tuple:
![](Database%20System/attachments/Pasted%20image%2020240814142948.png)
![](Database%20System/attachments/Pasted%20image%2020240814142743.png)

Then let's see all other tuples until the last one:
![](Database%20System/attachments/Pasted%20image%2020240814143052.png)

Let's see how this works in the Wikipedia example where we have someone wants to login with username and password:
```sql
SELECT * FROM useracct
WHERE userName = ?
AND userPass = ?
```

Without going into the details about how to retrieve the record ID given `userName` and `userPass`, let's just to the point where we go in the page directory and we find the page that has the data we are looking for, we look in the slot array, we jump to some offset and now we have all the data we need:
![](Database%20System/attachments/Pasted%20image%2020240814145004.png)

Again, this is ideal for OLTP because all the data is contiguously.

If we want to perform an insert all we need to do is to look in our page directory, find a page that has a free slot, go bring it to memory, and append to the end:
![](Database%20System/attachments/Pasted%20image%2020240814145732.png)

Let's try to run the complex query we have seen before representing an OLAP workload and let's see why the NSM is not suitable for it:
```sql
SELECT COUNT(U.lastLogin),
		EXTRACT(month FROM U.lastLogin) AS month
FROM useracct AS U
WHERE U.hostname LIKE '%.gov'
GROUP BY
EXTRACT(month FROM. U.lastLogin)
```
I need to scan all the pages in the table (because I need to look at all the user accounts), then I bring a page in and execute the query. The problem is that in this query only `lastLogin` and `hostname` attributes are relevant:
![](Database%20System/attachments/Pasted%20image%2020240814153950.png)
So, the obvious problem is that we brought a bunch of **data we actually don't need** (useless data, useless I/O)

### 2.1.2 NSM: Summary
+ **Advantages**
	+ fast insert, updates, and deletes
	+ good for queries that need the entire tuple (OLTP)
	+ can use index-oriented physical storage for clustering
+ **Disadvantages**
	+ not good for scanning large portions of the table and/or a subset of the attributes
	+ terrible memory locality in access patterns
	+ not idea for compression because of multiple value domains within a single page.
## 2.2. Decomposition Storage Model (DSM)
In the **Decomposition Storage Model**, the DBMS stores a single attribute (column) for all tuples contiguously in a block of data. Thus, it is also known as a “**column store**.” This model is ideal for OLAP workloads with many read-only queries that perform large scans over a subset of the table’s attributes that I really need.

Note again the benefit of a declerative language like SQL, where you don't care wether you're running on a row storage system or a column storage system. You write a query and it's the DBMS's responsibility to produce results in the best possible way.
### 2.2.1 DSM: Physical Organization
It maintains a separate file per attribute with a dedicated header area for metadata about entire column:
![](Database%20System/attachments/Pasted%20image%2020240814161415.png)

The DBMS stores the values of a single attribute across multiple tuples contiguously in a page. Also known as a "column store". Let's take again the Wikipedia example where we take every column of the table and we store that as a separate page:
![](Database%20System/attachments/Pasted%20image%2020240814170628.png)

Let's analyze the complex query again, but now with DSM, in particular let's focus first on the `hostname` attribute:
![](Database%20System/attachments/Pasted%20image%2020240814171335.png)
then let's focus on `lastLogin`:
![](Database%20System/attachments/Pasted%20image%2020240814181049.png)

Compared to NSM, now I have a 100% complete utilization of all the data that I brought in because I'm only bringing in the data I need for the query, and I'm not bringing in useless data.

We'll talk later on about query execution, but here's just an hint: from the `WHERE` clause, assume you keep track of a list of the offsets of the tuples within the `hostname` column that matches the condition in the query; then take those offsets and use them to fetch data for `lastLogin` attribute. How does this step happen? There's 2 approaches:
1. **Fixed-length Offsets**: each values is the same length for an attribute. The value in a given column will belong to the same tuple as the value in another column at the same offset. Therefore, every single value within the column will have to be the same length. Indeed this assumption is broken by varchar datatype.
2. **Embedded Tuple Ids**: each value is stored with its tuple id in a column. For every attribute in the columns, the DBMS stores a tuple id (ex: a primary key) with it. Then, the system would also store a mapping to tell it how to jump to every attribute that has that id. Note that this method has a large storage overhead because it needs to store a tuple id for every attribute entry.
![](Database%20System/attachments/Pasted%20image%2020240814210827.png)

*(These two approaches are not so clear to me. revise them asap)*

Since Fixed-length Offsets approach is more common, the problem we have to deal is how to convert variable-length values into fixed-length values. Solution: use **dictionary compression** to convert repetitive variable-length data into fixed-length values (typically 32-bit integers).
### 2.2.1 DSM: System History
* 1970s: Cantor DBMS
* 1980s: DSM Proposal
* 1990s: SybaseIQ (in-memory only)
* 2000s: Vertica, Vectorwise, MonetDB
### 2.2.2. DSM: Summary
* **Advantages**
	* reduces the amount wasted I/O per query because the DBMS only reads the data that it needs.
	* Faster query processing because of increased locality and cached data reuse. That's because we're literally going through columns one after another and not have to jump around within memory, which is better for CPUs.
	* Better data compression (more on this later).
* **Disadvantages**
	* slow for point queries, inserts, updates, and deletes because of tuple splitting/slitching/reorganization

### 2.2.3. Observation
OLAP queries almost never access a single column in a table by itself (in the previous query we queries against the `hostname` column, it's very common to query against many columns at the same time). At some point during query execution, the DBMS must get other columns and stich the original tuple back together. So, we need a way to have the attributes that are going to be used together somewhat closer to each other on disk or files, but still get all the benefit of a **column store** layout. That's what the PAX storage model is.
## 2.3. Hybrid Storage Model (PAX)
In the hybrid Partition Attributes Across storage model, the DBMS vertically partitions attributes within a database page (this is what Parquet and Orc use). The goal of doing so is to get the benefit of **faster processing** on columnar storage while retaining the **spatial locality** benefits of row storage.
### 2.3.1. PAX: Physical Organization
In PAX the rows are horizontally partitioned into groups of rows. Within each row group, the attributes are vertically partitioned into columns. Each row group is similar to a column store for its subset of the rows:
![](Database%20System/attachments/Pasted%20image%2020240814220101.png)
A PAX file has a global header containing a directory with offsets to the file’s row groups, and each row group maintains its own header with meta-data about its contents. Now, if I have a `WHERE` clause on both `Col A` and `Col B`, when I go fetch these pages for this row group, I have all the data for that I need close to each other. On the same time, I'm getting the benefit of I/O because this row group is going to be in tens of MB instead of 4 or 8 KB pages.

This is roughly how **Parquet** works.
# 3. Database Compression
Disk I/O is (almost) always the main bottleneck I/O. To speed up queries, you can skip data (that's what column-store systems do), but that's not the only way to do it. Another way is **Compression**: the DBMS can **compress** pages to increase the utility of the data moved per I/O operation (indeed it's widely used in disk-based DBMSs). The DBMS can fetch more useful tuples if they have been compressed beforehand at the cost of greater computational overhead for compression and decompression.

There is a trade-off that is **speed vs compression ratio**:
+ compressing the database reduces DRAM requirements
+ compressing may decrease CPU costs during query execution.

*(This introduction to Compression topic is not so clear. revise them asap)*

**Database Compression goals:**
1. must produce fixed-length values; this is because the DBMS should follow word-alignment and be able to access data using offsets.
2. postpone decompression for as long as possible during query execution (aka **late materialization**);
3. must be a **lossless** scheme.

**Lossless vs Lossy compression**
* when a DBMS uses compression, it is always **lossless** because people don't like losing data;
* any kind of **lossy** compression must be performed at the application level.
## 3.1. Compression Granularity
The kind of data we want to compress greatly affects which compression schemes can be used. There are four levels of compression granularity:
1. **Block-level**: compress a block of tuples for the same table.
2. **Tuple-level**: compress the contents of the entire tuple (NSM-only).
3. **Attribute-level**: compress a single attribute within one tuple (overflow); can target multiple attributes for the same tuple.
4. **Column-level**: compress multiple values for one or more attributes stored for multiple tuples (DSM-only).
## 3.2. Block-level Compression (Naive Compression)
"Naive" means that the DBMS is making a call to a third-part library (such as gzip) that's going to take the page and then compress it down to some binary form where the DBMS has no way to interpret or any can do any introspection into the compressed version of the block.

Some examples of general purpose algorithms: gzip, LZO, LZ4, Snappy, Brotli, Oracle OZIP, Zstd (from Facebook, it's considered the state-of-the-art compression scheme now).

An example of using naive compression is in **MySQL InnoDB**. The DBMS compresses disk pages, pads them to a power of 2KBs and stores them into the buffer pool. However, every time the DBMS tries to read/modify data, the compressed data in the buffer pool must first be decompressed:
![](Database%20System/attachments/Pasted%20image%2020240815172256.png)

If I'm doing a blind write (such as insert, or delete, or even update), I don't need to decompress the page I just write that change to the *mod log*. In some cases I can read on the mod log because if the data I need was just inserted and it's the mod log, I don't have to decompress the rest of the page.

*(This **MySQL InnoDB** part is not so clear. revise them asap)*

**Observations**
Ideally, we want the DBMS to operate on compressed data without decompressing it first. The easiest way to do is to go into a **Column-level** decompression type.
## 3.3. Column-level Compression
A bunch of compression algorithm in this category:
+ **Run-length Encoding**
+ **Bit-Packing Encoding**
+ **Bitmap Encoding**
+ **Delta Encoding**
+ **Incremental Encoding**
+ **Dictionary Encoding** (default choice for most systems). After you do dictionary encoding, you can apply all these other compression schemes on the dictionary itself or you're still your dictionary code of value and get even further compression. So you can sort of a multiplicative effect where you do compression one way and then you run another compression algorithm on the compressed data and get even better compression. And it's done in a way where the data system can natively interpret what those bytes actually means in the compressed form without having to decompress it first. And this is why you want the data system to do everything do everything and don't want the OS to do anything or anybody else do anything because we can do this native compression.
### 3.3.1 Run-length Encoding
The idea is: if you have contiguous runs of the same value, instead of throwing that value over and over again for every single tuple, all instead store a compressed summary that says: "for this value at this offset, here's how many occurrences it has." This works great if your data is sorted on whatever the column you're trying to compress.
